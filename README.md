# ğŸ“ˆ Telco Customer Churn Prediction

> **Machine learning project predicting telecom customer churn with 80.9% accuracy using PostgreSQL and Python**

## ğŸ¯ Project Overview

This project predicts which customers are likely to cancel their telecom services, enabling targeted retention strategies. Using a combination of PostgreSQL for data management and Python for machine learning, the model achieves **80.9% accuracy** and **85.3% AUC**, providing actionable insights for business decision-making.

### ğŸ† Key Results
- **Dataset:** 7,043 customer records from Kaggle Telco Customer Churn dataset
- **Churn Rate:** 26.54% of customers churned
- **Best Model:** Logistic Regression (80.9% accuracy, 85.3% AUC)
- **Business Impact:** $129,000 potential annual savings through targeted retention

## ğŸ” Key Business Insights

| Finding | Impact |
|---------|--------|
| ğŸ“‹ **Contract Type is #1 predictor** | Month-to-month: 42% churn vs Two-year: 3% churn |
| â° **Tenure matters** | New customers (0-10 months) show highest churn risk |
| ğŸŒ **Internet Service type** | Fiber optic customers churn more than DSL users |
| ğŸ’° **Monthly Charges** | Higher-paying customers are more likely to churn |

## ğŸ›  Technology Stack

- **Database:** PostgreSQL 15
- **Languages:** Python 3.11, SQL  
- **ML Libraries:** scikit-learn, pandas, numpy
- **Visualization:** matplotlib, seaborn
- **Environment:** Anaconda

## ğŸ“Š Model Performance

### Logistic Regression (Best Model)
```
Accuracy:     80.91%
ROC AUC:      85.26%
Precision:    68% (churn detection)  
Recall:       53% (churn detection)
```

### Business Metrics
- **Customer Lifetime Value:** ~$1,800
- **Retention Cost:** ~$50 per customer  
- **ROI:** 2,600% on targeted retention campaigns

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+ with Anaconda
- PostgreSQL 15+
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/AnthonyMerlinGoHokies/telco-churn-prediction.git
cd telco-churn-prediction
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Set up PostgreSQL database**
```bash
# Create database
createdb telco_churn

# Run setup script
psql -d telco_churn -f sql/create_database.sql
```

4. **Download dataset**
- Get `WA_Fn-UseC_-Telco-Customer-Churn.csv` from [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- Place in `data/` folder

5. **Load data and run analysis**
```bash
# Load data into PostgreSQL
python src/load_data.py

# Run complete ML analysis
python src/ml_analysis.py
```

## ğŸ“ Project Structure

```
telco-churn-prediction/
â”œâ”€â”€ ğŸ“„ README.md                          # Project overview
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python dependencies
â”œâ”€â”€ ğŸ“ data/                             # Dataset files
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ ğŸ“ sql/                              # Database setup
â”‚   â””â”€â”€ create_database.sql
â”œâ”€â”€ ğŸ“ src/                              # Source code
â”‚   â”œâ”€â”€ load_data.py                     # Data loading pipeline
â”‚   â””â”€â”€ ml_analysis.py                   # ML analysis pipeline
â”œâ”€â”€ ğŸ“ results/                          # Generated outputs
â”‚   â”œâ”€â”€ eda_analysis.png                 # Exploratory data visualizations
â”‚   â”œâ”€â”€ model_performance.png            # Model comparison charts
â”‚   â””â”€â”€ results_summary.txt              # Complete analysis summary
â””â”€â”€ ğŸ“ docs/                             # Additional documentation
```

## ğŸ“ˆ Visualizations

The project automatically generates comprehensive visualizations:


*Charts show churn patterns, contract analysis, model comparisons, and feature importance rankings*

## ğŸ’¼ Business Applications

1. **ğŸ¯ Risk Scoring:** Rank customers by churn probability
2. **ğŸ“ Targeted Campaigns:** Focus retention efforts on high-risk customers  
3. **ğŸ“‹ Product Strategy:** Promote long-term contracts to reduce churn
4. **ğŸ¤ Customer Success:** Proactive support for new customers

## ğŸ”¬ Methodology

1. **Data Engineering:** PostgreSQL database with proper indexing
2. **Feature Engineering:** Created `charges_per_tenure`, `is_new_customer` features
3. **Model Training:** Compared Logistic Regression vs Random Forest
4. **Evaluation:** Used accuracy, ROC AUC, precision, and recall metrics
5. **Business Validation:** Calculated ROI and cost-benefit analysis

## ğŸ“Š Dataset Information

- **Source:** [Kaggle Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- **Size:** 7,043 customers with 21 features
- **Target:** Binary classification (Churn: Yes/No)
- **Features:** Demographics, services, contract details, charges

## ğŸ”„ Workflow

```mermaid
graph LR
    A[Raw CSV Data] --> B[PostgreSQL Database]
    B --> C[Data Preprocessing]
    C --> D[Feature Engineering]
    D --> E[Model Training]
    E --> F[Model Evaluation]
    F --> G[Business Insights]
```

## ğŸš€ Future Enhancements

- [ ] Deploy model as REST API using Flask
- [ ] Create interactive dashboard with Streamlit
- [ ] Add customer segmentation analysis
- [ ] Implement real-time scoring pipeline
- [ ] A/B testing framework for retention strategies

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Dataset provided by IBM Watson Analytics
- Kaggle for hosting the dataset
- PostgreSQL and scikit-learn communities

## ğŸ“§ Contact

**Anthony Merlin**
- GitHub: [@AnthonyMerlinGoHokies](https://github.com/AnthonyMerlinGoHokies)
- LinkedIn: [Connect with me](https://linkedin.com/in/yourprofile)

---

â­ **Star this repository if you found it helpful!**
